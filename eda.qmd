---
title: "Exploratory Data Analysis"
format: html
---

# Data Preparation

The dataset [@sonadata2023] was comprised of a series of text files of the State of the Nation Addresses (SONA) from 1994 through 2022. Each speech's content was subsequently ingested, omitting the initial lines. These speeches were then collated into a structured format for more convenient access and manipulation.

Subsequently, essential metadata, including the year of the address and the name of the delivering president, were gleaned. Ater that, the removal of URLs, HTML character codes, and newline characters was performed. Additionally, the date of each address was extracted and appropriately formatted.

To achieve the project's objectives, each speech was dissected into its individual sentences. This granular breakdown facilitated the mapping of each sentence to its originating president. The finalised structured dataset comprises individual sentences paired with their respective presidents. This dataset was also saved as a csv file for future use.

For the model building, the data was prepared by create a 70-15-15 train-validation-test split, with the same seed being used for each method to ensure fair comparisons.

```{python}

# Loading in the necessary libraries
import zipfile
import os
import pandas as pd
import re
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS
from itertools import cycle
import seaborn as sns
import numpy as np
from collections import Counter
from nltk.tokenize import word_tokenize

```




```{python}

# Unzip the file and get the list of filenames
with zipfile.ZipFile("data/speeches.zip", 'r') as zip_ref:
    zip_ref.extractall("data")

filenames = os.listdir("data")
filenames = [filename for filename in filenames if filename.endswith('.txt')]

# Read the content of each speech file and extract the date from the first line
speeches = []
dates = []
for filename in filenames:
    with open(os.path.join("data", filename), 'r', encoding='utf-8') as file:
        # Extract date from the first line
        date = file.readline().strip()
        dates.append(date)
        
        # Read the rest of the file
        speeches.append(file.read())

# Create DataFrame
sona = pd.DataFrame({'filename': filenames, 'speech': speeches, 'date': dates})

# Extract year and president for each speech
sona['year'] = sona['filename'].str[:4]
sona['president'] = sona['filename'].str.split('_').str[-1].str.split('.').str[0]

# Clean the sona dataset by removing unnecessary text
replace_reg = r'(http.*?(\s|.$))|(www.*?(\s|.$))|&amp;|&lt;|&gt;|\n'
sona['speech'] = sona['speech'].str.replace(replace_reg, ' ')

# Split speeches into sentences
sona_sentences = sona['speech'].str.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?)\s', expand=True).stack().reset_index(level=-1, drop=True)
sona_sentences.name = 'sentence'

# Remove newline characters from the sentences
sona_sentences = sona_sentences.str.replace('\n', '').str.strip()

# Merge with the president, date, and year columns to associate each sentence with the respective details
df_sentences = sona[['president', 'date', 'year']].join(sona_sentences)

# Make a csv of the sentences
df_sentences.to_csv('data/sentences.csv', index=False)

```

## Number of speeches per president

```{python}

speeches_per_president = sona.groupby('president').size().reset_index(name='number_of_speeches')

# Display the table for number of speeches per president in a well-formatted manner
speeches_per_president.set_index('president', inplace=True)

# Plot the number of speeches per president
speeches_per_president.plot(kind='bar', legend=False, color='mediumpurple', edgecolor='black', ax=plt.gca())
plt.title('Number of Speeches per President')
plt.ylabel('Number of Speeches')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()


```

The bar plot above illustrates the total number of speeches given by each president. Mbeki and Zuma had most speeches in the dataset, with 10 each. This means that there's a substantial amount of data available for them, which could be advantageous when discerning their linguistic patterns, given that there is not a significant overlap in the sentences of the two presidents. Motlanthe and de Klerk only had one speech each, which may be an issue, due to an imbalance in the data, which may bias the model output later. To explore this further, the number of sentences per president is examined.

## Number of sentences per president

```{python}

sentences_per_president = df_sentences.groupby('president').size().reset_index(name='number_of_sentences')
sentences_per_president.plot(x='president', y='number_of_sentences', kind='bar', legend=False, color='skyblue', edgecolor='black')
plt.title('Number of Sentences per President')
plt.ylabel('Number of Sentences')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

```


The plot above gives a breakdown of the number of sentences spoken by each president. Zuma stands out with the most sentences, further underscoring his prominence in the dataset. Notably, while Mbeki gave three more speeches than Ramaphosa, their sentence count is nearly the same, implying that Ramaphosa's speeches might be more verbose or detailed. This data provides a deeper understanding of the granularity of each president's contribution and reaffirms the potential data imbalance to be addressed in model development, especially when considering the fact that de Klerk and Motlanthe have less than 300 sentences each, while the others have well over 1500.

## Average sentence length per president


```{python}

df_sentences['sentence_length'] = df_sentences['sentence'].str.split().str.len()
avg_sentence_length = df_sentences.groupby('president')['sentence_length'].mean().reset_index()

avg_sentence_length.plot(x='president', y='sentence_length', kind='bar', legend=False, color='lightcoral', edgecolor='black')
plt.title('Average Sentence Length per President')
plt.ylabel('Average Sentence Length (words)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()


```

This plot unveils the average sentence length, in words, for each president. A striking observation is that Zuma, despite having the most sentences and speeches, has a relatively concise average sentence length. Conversely, Mbeki and Motlanthe have longer average sentence lengths, with Mbeki being the only president that had over 30 words per sentence, on average. This metric offers insights into the verbosity and style of each president, which can be a useful feature when discerning speech patterns in model building.

## Word clouds for each president

```{python}

from itertools import cycle
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt

# Set the stopwords
stopwords = set(STOPWORDS)

# Selected colormaps
colormaps = cycle(['viridis', 'plasma', 'magma', 'cividis'])

# Adjusting the layout for the word clouds
plt.figure(figsize=(15, 30))

# Generate a word cloud for each president, with adjusted layout
for idx, (president, group) in enumerate(df_sentences.groupby('president')):
    text = ' '.join(group['sentence'])
    wc = WordCloud(stopwords=stopwords, background_color='white', colormap=next(colormaps), max_words=200, width=800, height=400).generate(text)
    
    # Display the word cloud
    plt.subplot(len(df_sentences['president'].unique()), 1, idx + 1)
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.title(president, fontdict={'fontsize': 20, 'fontweight': 'medium'})

plt.tight_layout()
plt.show()


```

The word clouds above offer a visually compelling representation of the most frequently used words by each president. The size of each word in the cloud corresponds to its frequency in the speeches. All the presidents had "will" as their most prominent word and referred to the country many times while speaking (highlighted by the use of the words "south" and "africa"/"african"). Motlanthe seemed to focus more on the economy and public image with the use of words such as "national", "public" and "government", whereas Mandela seemed to focus more on the people with the use of words such as "people" and "us". de Klerk focused more on the constitution and forming alliances during a transitional period, and Zuma focused more on work and the development. These word clouds provide a snapshot of the focal points and themes of each president's speeches. Distinctive words or terms can be potential features when building predictive models. The words from the wordclouds can also be seen in the bar plots below.

## Word frequency distribution for each president


```{python}

# Define a simple tokenizer function
def simple_tokenize(text):
    return [word for word in text.split() if word.isalpha()]

# Update the plotting function to use the simple tokenizer
def plot_word_frequency(text, president_name, n=10):
    tokens = simple_tokenize(text.lower())
    filtered_tokens = [word for word in tokens if word not in stopwords]
    frequency = Counter(filtered_tokens)
    most_common = frequency.most_common(n)
    
    words, counts = zip(*most_common)
    plt.bar(words, counts, color='lightseagreen')
    plt.title(f"Top {n} Words used by {president_name}")
    plt.xticks(rotation=45)
    plt.ylabel("Frequency")
    plt.show()

# Plot word frequency distribution for each president using the updated function
for president, group in df_sentences.groupby('president'):
    plot_word_frequency(' '.join(group['sentence']), president)



```


## N-gram frequency distributions for each president


### Bigrams

```{python}

# Define a function to generate n-grams
def generate_ngrams(text, n):
    tokens = simple_tokenize(text.lower())
    filtered_tokens = [word for word in tokens if word not in stopwords]
    ngrams = zip(*[filtered_tokens[i:] for i in range(n)])
    return [" ".join(ngram) for ngram in ngrams]

# Define function to plot N-gram frequency
def plot_ngram_frequency(text, president_name, n=2, top_n=10):
    ngrams = generate_ngrams(text, n)
    frequency = Counter(ngrams)
    most_common = frequency.most_common(top_n)
    
    phrases, counts = zip(*most_common)
    plt.bar(phrases, counts, color='lightsalmon')
    plt.title(f"Top {top_n} {n}-grams used by {president_name}")
    plt.xticks(rotation=45, ha='right')
    plt.ylabel("Frequency")
    plt.show()

# Plot bigram frequency distribution for each president
for president, group in df_sentences.groupby('president'):
    plot_ngram_frequency(' '.join(group['sentence']), president)


```


Instead of only looking at single word frequency, bigrams can also be used to find the most common two-word phrases. The bigrams above elucidate the distinctive linguistic patterns and thematic foci of each president, presenting opportunities for differentiation. For instance, President Mandela's frequently used bigrams, such as "South Africans" and "national unity," reflect his emphasis on nation-building and reconciliation during his tenure. In contrast, President Zuma's bigrams like "economic growth" suggest a policy-driven discourse concentrated on economic dynamics. However, there are potential pitfalls. Overlapping or common bigrams across presidents, such as generic terms or phrases prevalent in political discourse, could introduce ambiguity, potentially hindering the model's precision. Additionally, while President Ramaphosa's bigrams like "South Africa" are distinctly frequent, they are not uniquely attributable to him, as such phrases are likely universal across South African presidencies. 

## Trigrams

```{python}

# Plot trigram frequency distribution for each president
for president, group in df_sentences.groupby('president'):
    plot_ngram_frequency(' '.join(group['sentence']), president, n=3)


```


Expanding on the analysis of linguistic markers, trigrams offer insights into the most recurrent three-word sequences employed by each president. The trigram outputs above further refine our understanding of the unique verbal choices and thematic concerns of each leader. For instance, President Mandela's recurrent trigrams, such as "trade union movement", underscore his consistent focus on the working class of South Africa. Meanwhile, President Zuma's trigrams, such as "expaned public works" indicate a focus on the public sector as a whole. Conversely, the presence of generic or universally applicable trigrams, such as "state nation address", might pose challenges. These broadly-used trigrams, inherent to political addresses across presidencies, might dilute the distinctive features of individual presidents, complicating the model's task. Moreover, trigrams like "south africa will" from President Ramaphosa, although salient, are emblematic of speeches common to all presidents, making them less distinguishing. Thus, while trigrams can accentuate the nuances of each president's discourse, the model would benefit from discerning the balance between distinctiveness and generic trigram usage.


## Sentence similarity between presidents

```{python}
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.manifold import TSNE
from sklearn.feature_extraction.text import TfidfVectorizer
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences

def bow_x(data):
    # Extract relevant columns
    text_data = data['sentence']
    y = data['president']

    # Initialize a CountVectorizer for BOW representation
    vectorizer = CountVectorizer(lowercase=True, token_pattern=r"(?u)\b\w+\b", stop_words='english')

    # Fit and transform the text data
    X = vectorizer.fit_transform(text_data)

    # Create a DataFrame from the BOW representation
    bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())

    return bow_df


def tf_idf(df):
    sentences = df['sentence'].tolist()

    # Create a TfidfVectorizer with stop words removal
    tfidf_vectorizer = TfidfVectorizer(stop_words='english')

    # Fit and transform the sentences to compute TF-IDF values
    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)

    # Create a new dataframe with TF-IDF values
    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())

    return tfidf_df


def tokenize_text(text_data, labels, max_features=10000, maxlen=100):
    # Tokenization
    tokenizer = Tokenizer(num_words=max_features)
    tokenizer.fit_on_texts(text_data)
    sequences = tokenizer.texts_to_sequences(text_data)

    # Filter out sequences that have length 0
    seq_ok = [i for i, s in enumerate(sequences) if len(s) > 0]
    valid_labels = [labels.iloc[i] for i in seq_ok]

    # Padding sequences
    filtered_sequences = [sequences[i] for i in seq_ok]
    x_pad = pad_sequences(filtered_sequences, maxlen=maxlen)


    return x_pad, valid_labels, tokenizer

```


## Bag of Words (BOW) representation

```{python}

# Sample a subset of the data to alleviate memory issues
sample_df = df_sentences.sample(frac=0.4, random_state=1)

# 1. Encoding sentences using Bag of Words (BOW)
bow_encoded = bow_x(sample_df)
y_bow = sample_df['president']

# 2. Dimensionality reduction using t-SNE
tsne = TSNE(n_components=2, random_state=1)
bow_tsne = tsne.fit_transform(bow_encoded)

# 3. Visualise the results
plt.figure(figsize=(12, 8))
for president in sample_df['president'].unique():
    indices = [i for i, label in enumerate(y_bow) if label == president]
    plt.scatter(bow_tsne[indices, 0], bow_tsne[indices, 1], label=president, alpha=0.7)

plt.title('Visualisation of Sentences using Bag of Words (BOW)')
plt.legend()
plt.show()

```


The Bag-of-Words (BoW) visualisation above reveals a pronounced central cluster with substantial overlap across presidential sentences, indicating pervasive shared linguistic elements. This convergence towards common terms suggests that the BoW representation predominantly captures universal themes and terminologies characteristic of political discourse. Such patterns, while illuminating shared linguistic tendencies, underscore potential challenges in predictive modeling, with the BoW approach possibly lacking the granularity to detect distinctive linguistic markers for each president.

## TF-IDF representation

```{python}

# Encoding sentences using TF-IDF for the sample data
tfidf_encoded_sample = tf_idf(sample_df)

# Dimensionality reduction using t-SNE for the TF-IDF encoded data
tfidf_tsne_sample = tsne.fit_transform(tfidf_encoded_sample)

# Visualise the results for the TF-IDF encoded sample data
plt.figure(figsize=(12, 8))
for president in sample_df['president'].unique():
    indices = [i for i, label in enumerate(sample_df['president']) if label == president]
    plt.scatter(tfidf_tsne_sample[indices, 0], tfidf_tsne_sample[indices, 1], label=president, alpha=0.7)

plt.title('Visualisation of Sampled Sentences using TF-IDF')
plt.legend()
plt.show()


```

Using the TF-IDF representation, the visualization depicts a dominant central cluster, reaffirming the presence of overlapping linguistic constructs across presidential discourses. Unlike the BoW representation, the TF-IDF visualization lacks discernible smaller clusters, and data points appear more dispersed. This dispersion underscores the varied thematic undertones each president might have explored, but the pronounced overlap in the central region suggests that these thematic variations are not sufficiently distinct in the TF-IDF space to provide clear demarcations. The observed patterns emphasize the challenges inherent in solely relying on TF-IDF for capturing the unique linguistic nuances of each president.

## Tokenization with Padding representation

```{python}

# Encoding sentences using Tokenization with Padding for the sample data
x_pad_sample, valid_labels_sample, _ = tokenize_text(sample_df['sentence'], sample_df['president'])

# Dimensionality reduction using t-SNE for the Tokenized data
tokenized_tsne_sample = tsne.fit_transform(x_pad_sample)

# Visualise the results for the Tokenized sample data
plt.figure(figsize=(12, 8))
for president in sample_df['president'].unique():
    indices = [i for i, label in enumerate(valid_labels_sample) if label == president]
    plt.scatter(tokenized_tsne_sample[indices, 0], tokenized_tsne_sample[indices, 1], label=president, alpha=0.7)

plt.title('Visualisation of Sampled Sentences using Tokenization with Padding')
plt.legend()
plt.show()

```

Utilising tokenization with padding, the resultant visualization presents multiple clusters, indicating the method's ability to recognize shared linguistic constructs or thematic groupings within the dataset. Notably, the significant intermingling of presidents within these clusters underscores the shared nature of discourse patterns across different presidencies. The absence of a dominant central cluster, a divergence from the BoW and TF-IDF representations, alludes to a more nuanced and diverse sentence representation in the embedding space, potentially attributed to the emphasis on sentence structure inherent in the tokenization method.